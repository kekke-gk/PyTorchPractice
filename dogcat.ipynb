{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Dogs vs. Cats Redux: Kernels Edition](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)\n",
    "\n",
    "Kaggleの，犬と猫を分類するタスクに取り組む．\n",
    "\n",
    "\n",
    "このプログラムでは，\n",
    "- [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)を継承したデータセット読み込み用クラスの定義\n",
    "- [pretrainedmodels](https://github.com/Cadene/pretrained-models.pytorch)の学習済みモデルの利用\n",
    "- マルチGPU実行\n",
    "- [tensorboardX](https://github.com/lanpa/tensorboardX)を使い，TensorBoardでLoss・Accuracyを確認\n",
    "- モデルの保存・読み込み\n",
    "\n",
    "を行った．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'dogs-vs-cats-redux-kernels-edition'\n",
    "train_root = root + '/train'\n",
    "test_root = root + '/test'\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "image_size = 224\n",
    "resize_size = 256\n",
    "\n",
    "lr = .01\n",
    "momentum = .9\n",
    "\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ読み込み\n",
    "学習時のtransformでは，Data augmentationとしてランダムクロップとランダム水平フリップを行う．  \n",
    "テスト時は，中央をクリップして画像サイズを合わせる．\n",
    "\n",
    "PyTorchのデータセットを読み込む方法は主に3つあり，\n",
    "- [torchvision.datasets](https://pytorch.org/docs/stable/torchvision/datasets.html)を使う （公式に用意されたデータセットの場合）\n",
    "- [torchvision.datasets.ImageFolder](https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder)を使う （自分で用意したデータセットで，クラスごとにフォルダが分かれている場合）\n",
    "- [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)を継承したクラスを使う （それ以外の場合，例えばクラスを示すCSVがある場合など）\n",
    "\n",
    "今回は画像のファイル名が，犬か猫というクラスを表しているから，3つ目の方法をとる．  \n",
    "与えられたのはTrainとTestだけで，Validationのデータが用意されていないので，Trainの10分の1をValidationとして確保する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [transforms.Resize(resize_size),\n",
    "     transforms.RandomCrop(image_size),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                          std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.Resize(image_size),\n",
    "     transforms.CenterCrop(image_size),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                          std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "class DogCatTrainSet(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root_dir = Path(root)\n",
    "        self.transform = transform\n",
    "        filelist_dog = sorted(self.root_dir.glob('dog.*.jpg'))[:11250]\n",
    "        filelist_cat = sorted(self.root_dir.glob('cat.*.jpg'))[:11250]\n",
    "        self.filelist = filelist_dog + filelist_cat\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(str(self.filelist[idx]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        label = int(self.filelist[idx].name.startswith('cat'))  # dog: 0, cat: 1\n",
    "\n",
    "        return [image, label]\n",
    "\n",
    "class DogCatValidationSet(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root_dir = Path(root)\n",
    "        self.transform = transform\n",
    "        filelist_dog = sorted(self.root_dir.glob('dog.*.jpg'))[11250:]\n",
    "        filelist_cat = sorted(self.root_dir.glob('cat.*.jpg'))[11250:]\n",
    "        self.filelist = filelist_dog + filelist_cat\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(str(self.filelist[idx]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        label = int(self.filelist[idx].name.startswith('cat'))  # dog: 0, cat: 1\n",
    "\n",
    "        return [image, label]\n",
    "\n",
    "class DogCatTestSet(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root_dir = Path(root)\n",
    "        self.transform = transform\n",
    "        self.filelist = [self.root_dir.joinpath('{}.jpg'.format(i)) for i in range(1, 12500+1)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(str(self.filelist[idx]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image\n",
    "\n",
    "    \n",
    "train_set = DogCatTrainSet(root=train_root, transform=transform_train)\n",
    "validation_set = DogCatValidationSet(root=train_root, transform=transform_test)\n",
    "test_set = DogCatTestSet(root=test_root, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_set, num_workers=2, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, num_workers=2, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set, num_workers=2, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル定義\n",
    "ImageNetで学習済みのResNeXtを使う．  \n",
    "ResNeXtは公式で用意されていないので，[pretrainedmodels](https://github.com/Cadene/pretrained-models.pytorch)を使う．\n",
    "\n",
    "ImageNetで学習済みのモデルをFine tuneするため，ネットワークの前半は学習しないようにrequires_gradをFalseにして，出力層の出力次元を1000から2に変更する．\n",
    "\n",
    "[nn.DataParallel](https://pytorch.org/docs/stable/nn.html#torch.nn.DataParallel)でマルチGPU実行をする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pretrainedmodels.resnext101_64x4d(num_classes=1000, pretrained='imagenet')\n",
    "\n",
    "for p in model.features[:7].parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "model.last_linear = nn.Linear(2048, 2)\n",
    "\n",
    "model.cuda()\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, Optimizer\n",
    "ロスは[Cross Entropy](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss)，\n",
    "最適化は[Adam](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam)を使う．\n",
    "\n",
    "最適化関数のコンストラクタにmodel.parameters()を渡すと，requires_gradをFalseにしたことで学習できないパラメータがあるとエラーが出るので，学習する部分のパラメータのみ渡す．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.module.features[7].parameters(), lr=lr)\n",
    "optimizer.add_param_group({'params': model.module.last_linear.parameters()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorboardX\n",
    "[tensorboardX](https://github.com/lanpa/tensorboardX)は，TensorBoardで見れる形式でデータを書き出してくれる．\n",
    "学習時のLossや検証時のAccuracyを書き出すことで，TensorBoard上でグラフにして確認できる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        data, label = data.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = model(data)\n",
    "        \n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar('Train/Loss', loss.item(), len(train_loader) * (epoch - 1) + batch_idx)\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{:5}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検証関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, label in validation_loader:\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "            out = model(data)\n",
    "            val_loss += F.nll_loss(out, label, size_average=False).item()\n",
    "            pred = out.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "    \n",
    "    accuracy = 100. * correct / len(validation_loader.dataset)\n",
    "    writer.add_scalar('Validation/Accu', accuracy, epoch)\n",
    "    \n",
    "    val_loss /= len(validation_loader.dataset)\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        val_loss, correct, len(validation_loader.dataset), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト関数\n",
    "テストデータを学習したモデルで推論し，Softmaxに通して犬である確率を書き出す．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    model.eval()\n",
    "    \n",
    "    probs = np.array([])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.cuda()\n",
    "            out = model(data)\n",
    "            softmax = F.softmax(out)\n",
    "            probs = np.hstack([probs, softmax[:,0]])\n",
    "    \n",
    "    p = Path('submit')\n",
    "    p.mkdir(exist_ok=True)\n",
    "    with open(p.joinpath('dogsvscats.csv'), 'a') as f:\n",
    "        f.write('id,label\\n')\n",
    "        submit = np.array(list(zip(np.arange(1, len(probs)+1), probs)))\n",
    "        np.savetxt(f, submit, fmt='%d,%.8f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習\n",
    "20エポック学習，\n",
    "各エポックでテスト・モデルの保存をする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [    0/22500 (0%)]\tLoss: 0.664547\n",
      "Train Epoch: 1 [ 2000/22500 (9%)]\tLoss: 0.039342\n",
      "Train Epoch: 1 [ 4000/22500 (18%)]\tLoss: 0.049197\n",
      "Train Epoch: 1 [ 6000/22500 (27%)]\tLoss: 0.045172\n",
      "Train Epoch: 1 [ 8000/22500 (35%)]\tLoss: 0.036143\n",
      "Train Epoch: 1 [10000/22500 (44%)]\tLoss: 0.037868\n",
      "Train Epoch: 1 [12000/22500 (53%)]\tLoss: 0.196585\n",
      "Train Epoch: 1 [14000/22500 (62%)]\tLoss: 0.032759\n",
      "Train Epoch: 1 [16000/22500 (71%)]\tLoss: 0.224415\n",
      "Train Epoch: 1 [18000/22500 (80%)]\tLoss: 0.013995\n",
      "Train Epoch: 1 [20000/22500 (88%)]\tLoss: 0.033495\n",
      "Train Epoch: 1 [22000/22500 (97%)]\tLoss: 0.024425\n",
      "\n",
      "Validation set: Average loss: -5.6625, Accuracy: 2477/2500 (99%)\n",
      "\n",
      "Train Epoch: 2 [    0/22500 (0%)]\tLoss: 0.034231\n",
      "Train Epoch: 2 [ 2000/22500 (9%)]\tLoss: 0.023230\n",
      "Train Epoch: 2 [ 4000/22500 (18%)]\tLoss: 0.005318\n",
      "Train Epoch: 2 [ 6000/22500 (27%)]\tLoss: 0.027988\n",
      "Train Epoch: 2 [ 8000/22500 (35%)]\tLoss: 0.021700\n",
      "Train Epoch: 2 [10000/22500 (44%)]\tLoss: 0.013547\n",
      "Train Epoch: 2 [12000/22500 (53%)]\tLoss: 0.023091\n",
      "Train Epoch: 2 [14000/22500 (62%)]\tLoss: 0.030808\n",
      "Train Epoch: 2 [16000/22500 (71%)]\tLoss: 0.032587\n",
      "Train Epoch: 2 [18000/22500 (80%)]\tLoss: 0.041643\n",
      "Train Epoch: 2 [20000/22500 (88%)]\tLoss: 0.069262\n",
      "Train Epoch: 2 [22000/22500 (97%)]\tLoss: 0.016146\n",
      "\n",
      "Validation set: Average loss: -5.9791, Accuracy: 2477/2500 (99%)\n",
      "\n",
      "Train Epoch: 3 [    0/22500 (0%)]\tLoss: 0.033261\n",
      "Train Epoch: 3 [ 2000/22500 (9%)]\tLoss: 0.010297\n",
      "Train Epoch: 3 [ 4000/22500 (18%)]\tLoss: 0.074865\n",
      "Train Epoch: 3 [ 6000/22500 (27%)]\tLoss: 0.016339\n",
      "Train Epoch: 3 [ 8000/22500 (35%)]\tLoss: 0.012714\n",
      "Train Epoch: 3 [10000/22500 (44%)]\tLoss: 0.008838\n",
      "Train Epoch: 3 [12000/22500 (53%)]\tLoss: 0.015494\n",
      "Train Epoch: 3 [14000/22500 (62%)]\tLoss: 0.020132\n",
      "Train Epoch: 3 [16000/22500 (71%)]\tLoss: 0.014955\n",
      "Train Epoch: 3 [18000/22500 (80%)]\tLoss: 0.051704\n",
      "Train Epoch: 3 [20000/22500 (88%)]\tLoss: 0.020052\n",
      "Train Epoch: 3 [22000/22500 (97%)]\tLoss: 0.008154\n",
      "\n",
      "Validation set: Average loss: -7.0627, Accuracy: 2475/2500 (99%)\n",
      "\n",
      "Train Epoch: 4 [    0/22500 (0%)]\tLoss: 0.016268\n",
      "Train Epoch: 4 [ 2000/22500 (9%)]\tLoss: 0.005957\n",
      "Train Epoch: 4 [ 4000/22500 (18%)]\tLoss: 0.012175\n",
      "Train Epoch: 4 [ 6000/22500 (27%)]\tLoss: 0.032400\n",
      "Train Epoch: 4 [ 8000/22500 (35%)]\tLoss: 0.039956\n",
      "Train Epoch: 4 [10000/22500 (44%)]\tLoss: 0.055570\n",
      "Train Epoch: 4 [12000/22500 (53%)]\tLoss: 0.033886\n",
      "Train Epoch: 4 [14000/22500 (62%)]\tLoss: 0.014188\n",
      "Train Epoch: 4 [16000/22500 (71%)]\tLoss: 0.009859\n",
      "Train Epoch: 4 [18000/22500 (80%)]\tLoss: 0.015279\n",
      "Train Epoch: 4 [20000/22500 (88%)]\tLoss: 0.020861\n",
      "Train Epoch: 4 [22000/22500 (97%)]\tLoss: 0.008985\n",
      "\n",
      "Validation set: Average loss: -7.7675, Accuracy: 2484/2500 (99%)\n",
      "\n",
      "Train Epoch: 5 [    0/22500 (0%)]\tLoss: 0.016331\n",
      "Train Epoch: 5 [ 2000/22500 (9%)]\tLoss: 0.016115\n",
      "Train Epoch: 5 [ 4000/22500 (18%)]\tLoss: 0.016786\n",
      "Train Epoch: 5 [ 6000/22500 (27%)]\tLoss: 0.004812\n",
      "Train Epoch: 5 [ 8000/22500 (35%)]\tLoss: 0.010754\n",
      "Train Epoch: 5 [10000/22500 (44%)]\tLoss: 0.015853\n",
      "Train Epoch: 5 [12000/22500 (53%)]\tLoss: 0.009729\n",
      "Train Epoch: 5 [14000/22500 (62%)]\tLoss: 0.002111\n",
      "Train Epoch: 5 [16000/22500 (71%)]\tLoss: 0.014286\n",
      "Train Epoch: 5 [18000/22500 (80%)]\tLoss: 0.017123\n",
      "Train Epoch: 5 [20000/22500 (88%)]\tLoss: 0.033808\n",
      "Train Epoch: 5 [22000/22500 (97%)]\tLoss: 0.008972\n",
      "\n",
      "Validation set: Average loss: -8.8414, Accuracy: 2475/2500 (99%)\n",
      "\n",
      "Train Epoch: 6 [    0/22500 (0%)]\tLoss: 0.014689\n",
      "Train Epoch: 6 [ 2000/22500 (9%)]\tLoss: 0.012291\n",
      "Train Epoch: 6 [ 4000/22500 (18%)]\tLoss: 0.008323\n",
      "Train Epoch: 6 [ 6000/22500 (27%)]\tLoss: 0.019999\n",
      "Train Epoch: 6 [ 8000/22500 (35%)]\tLoss: 0.011333\n",
      "Train Epoch: 6 [10000/22500 (44%)]\tLoss: 0.014251\n",
      "Train Epoch: 6 [12000/22500 (53%)]\tLoss: 0.105013\n",
      "Train Epoch: 6 [14000/22500 (62%)]\tLoss: 0.004683\n",
      "Train Epoch: 6 [16000/22500 (71%)]\tLoss: 0.041823\n",
      "Train Epoch: 6 [18000/22500 (80%)]\tLoss: 0.010263\n",
      "Train Epoch: 6 [20000/22500 (88%)]\tLoss: 0.029334\n",
      "Train Epoch: 6 [22000/22500 (97%)]\tLoss: 0.019202\n",
      "\n",
      "Validation set: Average loss: -7.6158, Accuracy: 2485/2500 (99%)\n",
      "\n",
      "Train Epoch: 7 [    0/22500 (0%)]\tLoss: 0.014086\n",
      "Train Epoch: 7 [ 2000/22500 (9%)]\tLoss: 0.007183\n",
      "Train Epoch: 7 [ 4000/22500 (18%)]\tLoss: 0.009389\n",
      "Train Epoch: 7 [ 6000/22500 (27%)]\tLoss: 0.011426\n",
      "Train Epoch: 7 [ 8000/22500 (35%)]\tLoss: 0.000796\n",
      "Train Epoch: 7 [10000/22500 (44%)]\tLoss: 0.018730\n",
      "Train Epoch: 7 [12000/22500 (53%)]\tLoss: 0.011888\n",
      "Train Epoch: 7 [14000/22500 (62%)]\tLoss: 0.024796\n",
      "Train Epoch: 7 [16000/22500 (71%)]\tLoss: 0.012772\n",
      "Train Epoch: 7 [18000/22500 (80%)]\tLoss: 0.011517\n",
      "Train Epoch: 7 [20000/22500 (88%)]\tLoss: 0.015305\n",
      "Train Epoch: 7 [22000/22500 (97%)]\tLoss: 0.006238\n",
      "\n",
      "Validation set: Average loss: -11.8176, Accuracy: 2466/2500 (99%)\n",
      "\n",
      "Train Epoch: 8 [    0/22500 (0%)]\tLoss: 0.039984\n",
      "Train Epoch: 8 [ 2000/22500 (9%)]\tLoss: 0.029476\n",
      "Train Epoch: 8 [ 4000/22500 (18%)]\tLoss: 0.020992\n",
      "Train Epoch: 8 [ 6000/22500 (27%)]\tLoss: 0.002375\n",
      "Train Epoch: 8 [ 8000/22500 (35%)]\tLoss: 0.009977\n",
      "Train Epoch: 8 [10000/22500 (44%)]\tLoss: 0.014240\n",
      "Train Epoch: 8 [12000/22500 (53%)]\tLoss: 0.011828\n",
      "Train Epoch: 8 [14000/22500 (62%)]\tLoss: 0.004993\n",
      "Train Epoch: 8 [16000/22500 (71%)]\tLoss: 0.004146\n",
      "Train Epoch: 8 [18000/22500 (80%)]\tLoss: 0.008892\n",
      "Train Epoch: 8 [20000/22500 (88%)]\tLoss: 0.022081\n",
      "Train Epoch: 8 [22000/22500 (97%)]\tLoss: 0.007018\n",
      "\n",
      "Validation set: Average loss: -10.3610, Accuracy: 2479/2500 (99%)\n",
      "\n",
      "Train Epoch: 9 [    0/22500 (0%)]\tLoss: 0.021831\n",
      "Train Epoch: 9 [ 2000/22500 (9%)]\tLoss: 0.039088\n",
      "Train Epoch: 9 [ 4000/22500 (18%)]\tLoss: 0.038427\n",
      "Train Epoch: 9 [ 6000/22500 (27%)]\tLoss: 0.031508\n",
      "Train Epoch: 9 [ 8000/22500 (35%)]\tLoss: 0.002984\n",
      "Train Epoch: 9 [10000/22500 (44%)]\tLoss: 0.033525\n",
      "Train Epoch: 9 [12000/22500 (53%)]\tLoss: 0.020029\n",
      "Train Epoch: 9 [14000/22500 (62%)]\tLoss: 0.054583\n",
      "Train Epoch: 9 [16000/22500 (71%)]\tLoss: 0.015005\n",
      "Train Epoch: 9 [18000/22500 (80%)]\tLoss: 0.005692\n",
      "Train Epoch: 9 [20000/22500 (88%)]\tLoss: 0.040028\n",
      "Train Epoch: 9 [22000/22500 (97%)]\tLoss: 0.022380\n",
      "\n",
      "Validation set: Average loss: -10.5346, Accuracy: 2483/2500 (99%)\n",
      "\n",
      "Train Epoch: 10 [    0/22500 (0%)]\tLoss: 0.032054\n",
      "Train Epoch: 10 [ 2000/22500 (9%)]\tLoss: 0.002645\n",
      "Train Epoch: 10 [ 4000/22500 (18%)]\tLoss: 0.011150\n",
      "Train Epoch: 10 [ 6000/22500 (27%)]\tLoss: 0.004168\n",
      "Train Epoch: 10 [ 8000/22500 (35%)]\tLoss: 0.042243\n",
      "Train Epoch: 10 [10000/22500 (44%)]\tLoss: 0.020416\n",
      "Train Epoch: 10 [12000/22500 (53%)]\tLoss: 0.007604\n",
      "Train Epoch: 10 [14000/22500 (62%)]\tLoss: 0.008696\n",
      "Train Epoch: 10 [16000/22500 (71%)]\tLoss: 0.010979\n",
      "Train Epoch: 10 [18000/22500 (80%)]\tLoss: 0.004373\n",
      "Train Epoch: 10 [20000/22500 (88%)]\tLoss: 0.012602\n",
      "Train Epoch: 10 [22000/22500 (97%)]\tLoss: 0.013066\n",
      "\n",
      "Validation set: Average loss: -9.2898, Accuracy: 2478/2500 (99%)\n",
      "\n",
      "Train Epoch: 11 [    0/22500 (0%)]\tLoss: 0.026284\n",
      "Train Epoch: 11 [ 2000/22500 (9%)]\tLoss: 0.028771\n",
      "Train Epoch: 11 [ 4000/22500 (18%)]\tLoss: 0.000709\n",
      "Train Epoch: 11 [ 6000/22500 (27%)]\tLoss: 0.013484\n",
      "Train Epoch: 11 [ 8000/22500 (35%)]\tLoss: 0.006794\n",
      "Train Epoch: 11 [10000/22500 (44%)]\tLoss: 0.025232\n",
      "Train Epoch: 11 [12000/22500 (53%)]\tLoss: 0.003798\n",
      "Train Epoch: 11 [14000/22500 (62%)]\tLoss: 0.024138\n",
      "Train Epoch: 11 [16000/22500 (71%)]\tLoss: 0.004420\n",
      "Train Epoch: 11 [18000/22500 (80%)]\tLoss: 0.012517\n",
      "Train Epoch: 11 [20000/22500 (88%)]\tLoss: 0.002871\n",
      "Train Epoch: 11 [22000/22500 (97%)]\tLoss: 0.008788\n",
      "\n",
      "Validation set: Average loss: -11.0839, Accuracy: 2480/2500 (99%)\n",
      "\n",
      "Train Epoch: 12 [    0/22500 (0%)]\tLoss: 0.009328\n",
      "Train Epoch: 12 [ 2000/22500 (9%)]\tLoss: 0.014875\n",
      "Train Epoch: 12 [ 4000/22500 (18%)]\tLoss: 0.013411\n",
      "Train Epoch: 12 [ 6000/22500 (27%)]\tLoss: 0.004855\n",
      "Train Epoch: 12 [ 8000/22500 (35%)]\tLoss: 0.006516\n",
      "Train Epoch: 12 [10000/22500 (44%)]\tLoss: 0.001122\n",
      "Train Epoch: 12 [12000/22500 (53%)]\tLoss: 0.005929\n",
      "Train Epoch: 12 [14000/22500 (62%)]\tLoss: 0.000770\n",
      "Train Epoch: 12 [16000/22500 (71%)]\tLoss: 0.025544\n",
      "Train Epoch: 12 [18000/22500 (80%)]\tLoss: 0.008718\n",
      "Train Epoch: 12 [20000/22500 (88%)]\tLoss: 0.010074\n",
      "Train Epoch: 12 [22000/22500 (97%)]\tLoss: 0.008738\n",
      "\n",
      "Validation set: Average loss: -11.0239, Accuracy: 2481/2500 (99%)\n",
      "\n",
      "Train Epoch: 13 [    0/22500 (0%)]\tLoss: 0.003775\n",
      "Train Epoch: 13 [ 2000/22500 (9%)]\tLoss: 0.009758\n",
      "Train Epoch: 13 [ 4000/22500 (18%)]\tLoss: 0.009755\n",
      "Train Epoch: 13 [ 6000/22500 (27%)]\tLoss: 0.018213\n",
      "Train Epoch: 13 [ 8000/22500 (35%)]\tLoss: 0.001436\n",
      "Train Epoch: 13 [10000/22500 (44%)]\tLoss: 0.032532\n",
      "Train Epoch: 13 [12000/22500 (53%)]\tLoss: 0.012255\n",
      "Train Epoch: 13 [14000/22500 (62%)]\tLoss: 0.001631\n",
      "Train Epoch: 13 [16000/22500 (71%)]\tLoss: 0.018544\n",
      "Train Epoch: 13 [18000/22500 (80%)]\tLoss: 0.020483\n",
      "Train Epoch: 13 [20000/22500 (88%)]\tLoss: 0.021150\n",
      "Train Epoch: 13 [22000/22500 (97%)]\tLoss: 0.011272\n",
      "\n",
      "Validation set: Average loss: -11.3001, Accuracy: 2484/2500 (99%)\n",
      "\n",
      "Train Epoch: 14 [    0/22500 (0%)]\tLoss: 0.015428\n",
      "Train Epoch: 14 [ 2000/22500 (9%)]\tLoss: 0.003778\n",
      "Train Epoch: 14 [ 4000/22500 (18%)]\tLoss: 0.006718\n",
      "Train Epoch: 14 [ 6000/22500 (27%)]\tLoss: 0.005458\n",
      "Train Epoch: 14 [ 8000/22500 (35%)]\tLoss: 0.000416\n",
      "Train Epoch: 14 [10000/22500 (44%)]\tLoss: 0.009329\n",
      "Train Epoch: 14 [12000/22500 (53%)]\tLoss: 0.000293\n",
      "Train Epoch: 14 [14000/22500 (62%)]\tLoss: 0.004814\n",
      "Train Epoch: 14 [16000/22500 (71%)]\tLoss: 0.000823\n",
      "Train Epoch: 14 [18000/22500 (80%)]\tLoss: 0.006621\n",
      "Train Epoch: 14 [20000/22500 (88%)]\tLoss: 0.016703\n",
      "Train Epoch: 14 [22000/22500 (97%)]\tLoss: 0.002839\n",
      "\n",
      "Validation set: Average loss: -11.8151, Accuracy: 2483/2500 (99%)\n",
      "\n",
      "Train Epoch: 15 [    0/22500 (0%)]\tLoss: 0.004723\n",
      "Train Epoch: 15 [ 2000/22500 (9%)]\tLoss: 0.003667\n",
      "Train Epoch: 15 [ 4000/22500 (18%)]\tLoss: 0.002656\n",
      "Train Epoch: 15 [ 6000/22500 (27%)]\tLoss: 0.001792\n",
      "Train Epoch: 15 [ 8000/22500 (35%)]\tLoss: 0.014648\n",
      "Train Epoch: 15 [10000/22500 (44%)]\tLoss: 0.007181\n",
      "Train Epoch: 15 [12000/22500 (53%)]\tLoss: 0.010737\n",
      "Train Epoch: 15 [14000/22500 (62%)]\tLoss: 0.009961\n",
      "Train Epoch: 15 [16000/22500 (71%)]\tLoss: 0.004317\n",
      "Train Epoch: 15 [18000/22500 (80%)]\tLoss: 0.003694\n",
      "Train Epoch: 15 [20000/22500 (88%)]\tLoss: 0.004814\n",
      "Train Epoch: 15 [22000/22500 (97%)]\tLoss: 0.001370\n",
      "\n",
      "Validation set: Average loss: -10.5112, Accuracy: 2485/2500 (99%)\n",
      "\n",
      "Train Epoch: 16 [    0/22500 (0%)]\tLoss: 0.005860\n",
      "Train Epoch: 16 [ 2000/22500 (9%)]\tLoss: 0.004808\n",
      "Train Epoch: 16 [ 4000/22500 (18%)]\tLoss: 0.002059\n",
      "Train Epoch: 16 [ 6000/22500 (27%)]\tLoss: 0.019059\n",
      "Train Epoch: 16 [ 8000/22500 (35%)]\tLoss: 0.000404\n",
      "Train Epoch: 16 [10000/22500 (44%)]\tLoss: 0.001306\n",
      "Train Epoch: 16 [12000/22500 (53%)]\tLoss: 0.000879\n",
      "Train Epoch: 16 [14000/22500 (62%)]\tLoss: 0.014644\n",
      "Train Epoch: 16 [16000/22500 (71%)]\tLoss: 0.022965\n",
      "Train Epoch: 16 [18000/22500 (80%)]\tLoss: 0.004271\n",
      "Train Epoch: 16 [20000/22500 (88%)]\tLoss: 0.006567\n",
      "Train Epoch: 16 [22000/22500 (97%)]\tLoss: 0.028814\n",
      "\n",
      "Validation set: Average loss: -10.5020, Accuracy: 2485/2500 (99%)\n",
      "\n",
      "Train Epoch: 17 [    0/22500 (0%)]\tLoss: 0.014392\n",
      "Train Epoch: 17 [ 2000/22500 (9%)]\tLoss: 0.004709\n",
      "Train Epoch: 17 [ 4000/22500 (18%)]\tLoss: 0.027003\n",
      "Train Epoch: 17 [ 6000/22500 (27%)]\tLoss: 0.002427\n",
      "Train Epoch: 17 [ 8000/22500 (35%)]\tLoss: 0.007667\n",
      "Train Epoch: 17 [10000/22500 (44%)]\tLoss: 0.005697\n",
      "Train Epoch: 17 [12000/22500 (53%)]\tLoss: 0.001982\n",
      "Train Epoch: 17 [14000/22500 (62%)]\tLoss: 0.000924\n",
      "Train Epoch: 17 [16000/22500 (71%)]\tLoss: 0.028176\n",
      "Train Epoch: 17 [18000/22500 (80%)]\tLoss: 0.013501\n",
      "Train Epoch: 17 [20000/22500 (88%)]\tLoss: 0.000952\n",
      "Train Epoch: 17 [22000/22500 (97%)]\tLoss: 0.008617\n",
      "\n",
      "Validation set: Average loss: -12.6114, Accuracy: 2482/2500 (99%)\n",
      "\n",
      "Train Epoch: 18 [    0/22500 (0%)]\tLoss: 0.004276\n",
      "Train Epoch: 18 [ 2000/22500 (9%)]\tLoss: 0.002366\n",
      "Train Epoch: 18 [ 4000/22500 (18%)]\tLoss: 0.002496\n",
      "Train Epoch: 18 [ 6000/22500 (27%)]\tLoss: 0.010801\n",
      "Train Epoch: 18 [ 8000/22500 (35%)]\tLoss: 0.005179\n",
      "Train Epoch: 18 [10000/22500 (44%)]\tLoss: 0.028464\n",
      "Train Epoch: 18 [12000/22500 (53%)]\tLoss: 0.000949\n",
      "Train Epoch: 18 [14000/22500 (62%)]\tLoss: 0.009845\n",
      "Train Epoch: 18 [16000/22500 (71%)]\tLoss: 0.000358\n",
      "Train Epoch: 18 [18000/22500 (80%)]\tLoss: 0.007653\n",
      "Train Epoch: 18 [20000/22500 (88%)]\tLoss: 0.001687\n",
      "Train Epoch: 18 [22000/22500 (97%)]\tLoss: 0.009927\n",
      "\n",
      "Validation set: Average loss: -12.7384, Accuracy: 2485/2500 (99%)\n",
      "\n",
      "Train Epoch: 19 [    0/22500 (0%)]\tLoss: 0.001695\n",
      "Train Epoch: 19 [ 2000/22500 (9%)]\tLoss: 0.000178\n",
      "Train Epoch: 19 [ 4000/22500 (18%)]\tLoss: 0.001945\n",
      "Train Epoch: 19 [ 6000/22500 (27%)]\tLoss: 0.000504\n",
      "Train Epoch: 19 [ 8000/22500 (35%)]\tLoss: 0.002835\n",
      "Train Epoch: 19 [10000/22500 (44%)]\tLoss: 0.000791\n",
      "Train Epoch: 19 [12000/22500 (53%)]\tLoss: 0.009655\n",
      "Train Epoch: 19 [14000/22500 (62%)]\tLoss: 0.001080\n",
      "Train Epoch: 19 [16000/22500 (71%)]\tLoss: 0.021961\n",
      "Train Epoch: 19 [18000/22500 (80%)]\tLoss: 0.005438\n",
      "Train Epoch: 19 [20000/22500 (88%)]\tLoss: 0.001319\n",
      "Train Epoch: 19 [22000/22500 (97%)]\tLoss: 0.000263\n",
      "\n",
      "Validation set: Average loss: -16.3514, Accuracy: 2485/2500 (99%)\n",
      "\n",
      "Train Epoch: 20 [    0/22500 (0%)]\tLoss: 0.000938\n",
      "Train Epoch: 20 [ 2000/22500 (9%)]\tLoss: 0.002440\n",
      "Train Epoch: 20 [ 4000/22500 (18%)]\tLoss: 0.006515\n",
      "Train Epoch: 20 [ 6000/22500 (27%)]\tLoss: 0.011912\n",
      "Train Epoch: 20 [ 8000/22500 (35%)]\tLoss: 0.004468\n",
      "Train Epoch: 20 [10000/22500 (44%)]\tLoss: 0.005349\n",
      "Train Epoch: 20 [12000/22500 (53%)]\tLoss: 0.005263\n",
      "Train Epoch: 20 [14000/22500 (62%)]\tLoss: 0.001915\n",
      "Train Epoch: 20 [16000/22500 (71%)]\tLoss: 0.005555\n",
      "Train Epoch: 20 [18000/22500 (80%)]\tLoss: 0.017820\n",
      "Train Epoch: 20 [20000/22500 (88%)]\tLoss: 0.005903\n",
      "Train Epoch: 20 [22000/22500 (97%)]\tLoss: 0.003453\n",
      "\n",
      "Validation set: Average loss: -13.8711, Accuracy: 2476/2500 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for i in range(epochs):\n",
    "    train(i + 1)\n",
    "    validation(i + 1)\n",
    "    torch.save(model.state_dict(), 'models/model_epoch_' + str(i + 1))\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト画像を推論\n",
    "Validationの精度が最も高いモデルを読み込み，\n",
    "testデータで推論して，Kaggleに提出するためのファイルを保存する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'models/model_epoch_19'\n",
    "model.load_state_dict(torch.load(model_name))\n",
    "\n",
    "predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 付録\n",
    "\n",
    "![Train/Loss](trainloss.png)\n",
    "![Val/Accu](valaccu.png)\n",
    "![KaggleSubmit](kaggleres.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "python3_anaconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
